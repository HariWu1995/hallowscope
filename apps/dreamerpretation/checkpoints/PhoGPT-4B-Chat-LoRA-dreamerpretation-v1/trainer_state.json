{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 68.0,
  "eval_steps": 500,
  "global_step": 2465,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.993103448275862,
      "grad_norm": 0.33699050545692444,
      "learning_rate": 9.997532801828658e-05,
      "loss": 1.9993,
      "step": 36
    },
    {
      "epoch": 1.986206896551724,
      "grad_norm": 0.30989742279052734,
      "learning_rate": 9.990133642141359e-05,
      "loss": 1.3107,
      "step": 72
    },
    {
      "epoch": 2.979310344827586,
      "grad_norm": 0.42069754004478455,
      "learning_rate": 9.978218552534148e-05,
      "loss": 1.2086,
      "step": 108
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.8354629278182983,
      "learning_rate": 9.96057350657239e-05,
      "loss": 1.0528,
      "step": 145
    },
    {
      "epoch": 4.993103448275862,
      "grad_norm": 0.8108908534049988,
      "learning_rate": 9.938441702975689e-05,
      "loss": 0.932,
      "step": 181
    },
    {
      "epoch": 5.9862068965517246,
      "grad_norm": 1.1052852869033813,
      "learning_rate": 9.911436253643445e-05,
      "loss": 0.7816,
      "step": 217
    },
    {
      "epoch": 6.979310344827586,
      "grad_norm": 1.2693125009536743,
      "learning_rate": 9.879583809693738e-05,
      "loss": 0.6629,
      "step": 253
    },
    {
      "epoch": 8.0,
      "grad_norm": 1.788532018661499,
      "learning_rate": 9.841828847398493e-05,
      "loss": 0.5604,
      "step": 290
    },
    {
      "epoch": 8.993103448275862,
      "grad_norm": 1.44670832157135,
      "learning_rate": 9.800249271929645e-05,
      "loss": 0.5191,
      "step": 326
    },
    {
      "epoch": 9.986206896551725,
      "grad_norm": 1.4095432758331299,
      "learning_rate": 9.753932429970518e-05,
      "loss": 0.473,
      "step": 362
    },
    {
      "epoch": 10.979310344827587,
      "grad_norm": 1.395796298980713,
      "learning_rate": 9.702924030652228e-05,
      "loss": 0.4401,
      "step": 398
    },
    {
      "epoch": 12.0,
      "grad_norm": 1.3690029382705688,
      "learning_rate": 9.645662857670281e-05,
      "loss": 0.4126,
      "step": 435
    },
    {
      "epoch": 12.993103448275862,
      "grad_norm": 1.167000412940979,
      "learning_rate": 9.58530037192562e-05,
      "loss": 0.413,
      "step": 471
    },
    {
      "epoch": 13.986206896551725,
      "grad_norm": 0.8382693529129028,
      "learning_rate": 9.520412748303893e-05,
      "loss": 0.4021,
      "step": 507
    },
    {
      "epoch": 14.979310344827587,
      "grad_norm": 0.8857777714729309,
      "learning_rate": 9.451064023055633e-05,
      "loss": 0.3961,
      "step": 543
    },
    {
      "epoch": 16.0,
      "grad_norm": 1.0260674953460693,
      "learning_rate": 9.375212251305763e-05,
      "loss": 0.3782,
      "step": 580
    },
    {
      "epoch": 16.99310344827586,
      "grad_norm": 0.5827215313911438,
      "learning_rate": 9.297032057507264e-05,
      "loss": 0.384,
      "step": 616
    },
    {
      "epoch": 17.986206896551725,
      "grad_norm": 0.5205026268959045,
      "learning_rate": 9.214611211854974e-05,
      "loss": 0.3805,
      "step": 652
    },
    {
      "epoch": 18.979310344827585,
      "grad_norm": 0.5064484477043152,
      "learning_rate": 9.128031053772759e-05,
      "loss": 0.3774,
      "step": 688
    },
    {
      "epoch": 20.0,
      "grad_norm": 0.5754719376564026,
      "learning_rate": 9.034801560719011e-05,
      "loss": 0.3651,
      "step": 725
    },
    {
      "epoch": 20.99310344827586,
      "grad_norm": 0.4379187822341919,
      "learning_rate": 8.940053768033609e-05,
      "loss": 0.3736,
      "step": 761
    },
    {
      "epoch": 21.986206896551725,
      "grad_norm": 0.4196651875972748,
      "learning_rate": 8.841417617967618e-05,
      "loss": 0.3715,
      "step": 797
    },
    {
      "epoch": 22.979310344827585,
      "grad_norm": 0.4299103319644928,
      "learning_rate": 8.73899045249266e-05,
      "loss": 0.3702,
      "step": 833
    },
    {
      "epoch": 24.0,
      "grad_norm": 0.5731379389762878,
      "learning_rate": 8.629873987111632e-05,
      "loss": 0.359,
      "step": 870
    },
    {
      "epoch": 24.99310344827586,
      "grad_norm": 0.43490931391716003,
      "learning_rate": 8.520073622279842e-05,
      "loss": 0.3687,
      "step": 906
    },
    {
      "epoch": 25.986206896551725,
      "grad_norm": 0.44341304898262024,
      "learning_rate": 8.4067993697665e-05,
      "loss": 0.3678,
      "step": 942
    },
    {
      "epoch": 26.979310344827585,
      "grad_norm": 0.40961217880249023,
      "learning_rate": 8.290163017583072e-05,
      "loss": 0.3669,
      "step": 978
    },
    {
      "epoch": 28.0,
      "grad_norm": 0.5463850498199463,
      "learning_rate": 8.16690436313775e-05,
      "loss": 0.3561,
      "step": 1015
    },
    {
      "epoch": 28.99310344827586,
      "grad_norm": 0.3861711323261261,
      "learning_rate": 8.043807145043604e-05,
      "loss": 0.3652,
      "step": 1051
    },
    {
      "epoch": 29.986206896551725,
      "grad_norm": 0.4016183912754059,
      "learning_rate": 7.917706056780587e-05,
      "loss": 0.3644,
      "step": 1087
    },
    {
      "epoch": 30.979310344827585,
      "grad_norm": 0.5057440400123596,
      "learning_rate": 7.788725544898452e-05,
      "loss": 0.3632,
      "step": 1123
    },
    {
      "epoch": 32.0,
      "grad_norm": 0.5603837370872498,
      "learning_rate": 7.653295619678238e-05,
      "loss": 0.3532,
      "step": 1160
    },
    {
      "epoch": 32.99310344827586,
      "grad_norm": 0.5067095756530762,
      "learning_rate": 7.518869885227631e-05,
      "loss": 0.3628,
      "step": 1196
    },
    {
      "epoch": 33.98620689655172,
      "grad_norm": 0.6217473745346069,
      "learning_rate": 7.381958330307153e-05,
      "loss": 0.3612,
      "step": 1232
    },
    {
      "epoch": 34.97931034482759,
      "grad_norm": 1.2015182971954346,
      "learning_rate": 7.242696070091975e-05,
      "loss": 0.3616,
      "step": 1268
    },
    {
      "epoch": 36.0,
      "grad_norm": 0.5140430331230164,
      "learning_rate": 7.097260412230886e-05,
      "loss": 0.3497,
      "step": 1305
    },
    {
      "epoch": 36.99310344827586,
      "grad_norm": 1.3748598098754883,
      "learning_rate": 6.953655642446368e-05,
      "loss": 0.3595,
      "step": 1341
    },
    {
      "epoch": 37.98620689655172,
      "grad_norm": 0.9869793653488159,
      "learning_rate": 6.808122850410461e-05,
      "loss": 0.3577,
      "step": 1377
    },
    {
      "epoch": 38.97931034482759,
      "grad_norm": 0.7708079218864441,
      "learning_rate": 6.660805659418516e-05,
      "loss": 0.3593,
      "step": 1413
    },
    {
      "epoch": 40.0,
      "grad_norm": 0.5973814129829407,
      "learning_rate": 6.507689799722478e-05,
      "loss": 0.3488,
      "step": 1450
    },
    {
      "epoch": 40.99310344827586,
      "grad_norm": 0.38882753252983093,
      "learning_rate": 6.357202249325371e-05,
      "loss": 0.3566,
      "step": 1486
    },
    {
      "epoch": 41.98620689655172,
      "grad_norm": 1.4361402988433838,
      "learning_rate": 6.205375304165194e-05,
      "loss": 0.3567,
      "step": 1522
    },
    {
      "epoch": 42.97931034482759,
      "grad_norm": 0.8806288838386536,
      "learning_rate": 6.052358799106528e-05,
      "loss": 0.358,
      "step": 1558
    },
    {
      "epoch": 44.0,
      "grad_norm": 0.6072618961334229,
      "learning_rate": 5.8940110755817476e-05,
      "loss": 0.3457,
      "step": 1595
    },
    {
      "epoch": 44.99310344827586,
      "grad_norm": 1.1950509548187256,
      "learning_rate": 5.7390470556480545e-05,
      "loss": 0.3574,
      "step": 1631
    },
    {
      "epoch": 45.98620689655172,
      "grad_norm": 0.9179363250732422,
      "learning_rate": 5.583353685496666e-05,
      "loss": 0.3538,
      "step": 1667
    },
    {
      "epoch": 46.97931034482759,
      "grad_norm": 0.36001598834991455,
      "learning_rate": 5.427084615686838e-05,
      "loss": 0.3551,
      "step": 1703
    },
    {
      "epoch": 48.0,
      "grad_norm": 0.552836537361145,
      "learning_rate": 5.266037024368682e-05,
      "loss": 0.3442,
      "step": 1740
    },
    {
      "epoch": 48.99310344827586,
      "grad_norm": 1.1369825601577759,
      "learning_rate": 5.1090744251728064e-05,
      "loss": 0.3545,
      "step": 1776
    },
    {
      "epoch": 49.98620689655172,
      "grad_norm": 0.5276713371276855,
      "learning_rate": 4.952004182687999e-05,
      "loss": 0.3538,
      "step": 1812
    },
    {
      "epoch": 50.97931034482759,
      "grad_norm": 0.6338579058647156,
      "learning_rate": 4.7949813062802745e-05,
      "loss": 0.3519,
      "step": 1848
    },
    {
      "epoch": 52.0,
      "grad_norm": 0.4755907952785492,
      "learning_rate": 4.633809014361843e-05,
      "loss": 0.3406,
      "step": 1885
    },
    {
      "epoch": 52.99310344827586,
      "grad_norm": 1.2623870372772217,
      "learning_rate": 4.477357683661734e-05,
      "loss": 0.3507,
      "step": 1921
    },
    {
      "epoch": 53.98620689655172,
      "grad_norm": 0.6300040483474731,
      "learning_rate": 4.321422137828479e-05,
      "loss": 0.348,
      "step": 1957
    },
    {
      "epoch": 54.97931034482759,
      "grad_norm": 0.3935222625732422,
      "learning_rate": 4.166156266419489e-05,
      "loss": 0.3477,
      "step": 1993
    },
    {
      "epoch": 56.0,
      "grad_norm": 1.140487551689148,
      "learning_rate": 4.007436435069027e-05,
      "loss": 0.3394,
      "step": 2030
    },
    {
      "epoch": 56.99310344827586,
      "grad_norm": 0.6325858235359192,
      "learning_rate": 3.8539980453879304e-05,
      "loss": 0.3456,
      "step": 2066
    },
    {
      "epoch": 57.98620689655172,
      "grad_norm": 0.7503690719604492,
      "learning_rate": 3.701690621277544e-05,
      "loss": 0.3445,
      "step": 2102
    },
    {
      "epoch": 58.97931034482759,
      "grad_norm": 0.4478144645690918,
      "learning_rate": 3.5506644717771644e-05,
      "loss": 0.3429,
      "step": 2138
    },
    {
      "epoch": 60.0,
      "grad_norm": 0.484671950340271,
      "learning_rate": 3.396935047071619e-05,
      "loss": 0.3351,
      "step": 2175
    },
    {
      "epoch": 60.99310344827586,
      "grad_norm": 1.6568164825439453,
      "learning_rate": 3.248963093702663e-05,
      "loss": 0.3457,
      "step": 2211
    },
    {
      "epoch": 61.98620689655172,
      "grad_norm": 1.358985185623169,
      "learning_rate": 3.102719202354974e-05,
      "loss": 0.343,
      "step": 2247
    },
    {
      "epoch": 62.97931034482759,
      "grad_norm": 0.44250357151031494,
      "learning_rate": 2.958347698093077e-05,
      "loss": 0.3411,
      "step": 2283
    },
    {
      "epoch": 64.0,
      "grad_norm": 1.0221993923187256,
      "learning_rate": 2.8120668290049085e-05,
      "loss": 0.3312,
      "step": 2320
    },
    {
      "epoch": 64.99310344827586,
      "grad_norm": 2.833986282348633,
      "learning_rate": 2.671927398374443e-05,
      "loss": 0.3412,
      "step": 2356
    },
    {
      "epoch": 65.98620689655172,
      "grad_norm": 0.404733806848526,
      "learning_rate": 2.534085494330173e-05,
      "loss": 0.3393,
      "step": 2392
    },
    {
      "epoch": 66.97931034482758,
      "grad_norm": 0.4825092554092407,
      "learning_rate": 2.39867715018953e-05,
      "loss": 0.3389,
      "step": 2428
    },
    {
      "epoch": 68.0,
      "grad_norm": 4.135566711425781,
      "learning_rate": 2.2621838825372493e-05,
      "loss": 0.3312,
      "step": 2465
    }
  ],
  "logging_steps": 10,
  "max_steps": 3600,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 100,
  "save_steps": 10,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.427472636936192e+17,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
